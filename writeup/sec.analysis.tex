\section{Analysis}

Usually, implementations of inference algorithms for probabilistic models work with generic IDs. Depending on the application, different preprocessing steps may be necessary to assign IDs to entities. When working with customer data for example, one can use the customer ID from the customer relationship management system. On the other hand when working with image or text data, preprocessing steps are necessary to cope with these unstructured data.

[TODO: describe that all models just work with IDs: pre- and postprocessing steps may be necessary for meaningful visualization / interpretation]

\textbf{Questions}
\begin{itemize}
\item how is the analysis related to the statistical model or similar ones?
\item what are the assumptions made when new probabilities are computed?
\item when can OLAP / POLAP be applied?
\end{itemize}

\textbf{Filtering operations}\\
Select entities that have certain properties. Properties may be either domain specific meta data, inferred variables or both.
\begin{itemize}
\item documents belonging to specific cluster $c$ (\texttt{WHERE $z = c$})
\item documents having specific author $a$ (\texttt{WHERE $\textrm{Author} = a$})
\item clusters assigning at least 50\,\% probability to word $w$
\end{itemize}

\textbf{Ranking operations}\\
Order entities by atomic or aggregated variables (inferred or given).
\begin{itemize}
\item top documents of author
\item top words of clusters (\texttt{GROUP BY \textrm{Cluster.ID} ORDER BY $\mu$})
\item top clusters per word (\texttt{GROUP BY \textrm{Word.ID} ORDER BY $\mu$})
\end{itemize}

\textbf{Aggregation operations}\\
Counting, averaging, max / min operations on entities and relationships.
\begin{itemize}
\item number of documents per cluster
\item number of tokens per document
\item average number of tokens of documents per cluster
\item cluster with maximum prior probability ($\pi$)
\end{itemize}
